{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что я пробовала:\n",
    "- Добавить родительский комментарий;\n",
    "- Увеличить тренировочную выборку до 0.9;\n",
    "- Тренировать эмбединги с рандомной инициализацией; \n",
    "- Оставить знаки препинания. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, LabelField, BucketIterator, ReversibleField, TabularDataset\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "spacy_en.remove_pipe('tagger')\n",
    "spacy_en.remove_pipe('ner')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.lemma_ for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "fe81d9405992b26ddc651a8cb81e6b0f0501fdab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True,\n",
    "             stop_words=nltk.corpus.stopwords.words('english')\n",
    "            )\n",
    "LABEL = LabelField(dtype=tt.int64, use_vocab=True)\n",
    "\n",
    "dataset = TabularDataset('../input/train-balanced-sarcasm.csv', format='csv', \n",
    "                         fields=[('label', LABEL), ('text', TEXT),\n",
    "                                 (None, None),(None, None),(None, None),(None, None),\n",
    "                                 (None, None),(None, None),(None, None),\n",
    "                                 ('parent_comment', TEXT)], \n",
    "                                 skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9576ca271f370238cf15a446687d854d6a656c53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68344"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(dataset, min_freq=5)\n",
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ef108eaee3c72ce3130f827ee446b799a00afa33",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7a1d1f5d3b3d456bac25736b76fb503dfde484ad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = dataset.split(0.8, stratified=True)\n",
    "train, valid = train.split(0.9, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5277b60393e429475cfd59ed7706a4767d55d273"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1'], dtype='<U1'), array([363897, 363897]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in train.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "c30c267e77c043e6437e672203ead18fb2c27d6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = tt.device(\"cuda\" if tt.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d5ffbbd0416ed768b58cc805122e5de932ce3194",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = tt.nn.Embedding(vocab_size, embed_size)\n",
    "        tt.nn.init.uniform_(self.embedding.weight)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=embed_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                          )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2 *2, 3)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        x, x_lengths = batch.text\n",
    "        x = x.to(device)\n",
    "        batch.label = batch.label.to(device)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if x_lengths is not None:\n",
    "            x_lengths = x_lengths.view(-1).tolist()\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "            \n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        \n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ab991b58fada2e12dc4e46273509841b01aeadcd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt.cuda.empty_cache()\n",
    "batch_size = 32\n",
    "\n",
    "model = MyModel(len(TEXT.vocab.itos),\n",
    "                embed_size=100,\n",
    "                hidden_size=128,\n",
    "               )\n",
    "model = model.to(device)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(batch_size, batch_size, batch_size),\n",
    "    shuffle=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "61c21c10106c1a03790699089aa0e8e093827923",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.data.cpu().detach().item()\n",
    "        \n",
    "        loss_smoothing = i / (i+1)\n",
    "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
    "\n",
    "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
    "\n",
    "    return running_loss\n",
    "\n",
    "def _test_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    with tt.no_grad():\n",
    "        for batch in iterator:\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, batch.label)\n",
    "            epoch_loss += loss.data.item()\n",
    "\n",
    "    return epoch_loss / n_batches\n",
    "\n",
    "\n",
    "def nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=100,\n",
    "          scheduler=None, early_stopping=0):\n",
    "\n",
    "    prev_loss = 100500\n",
    "    es_epochs = 0\n",
    "    best_epoch = None\n",
    "    history = pd.DataFrame()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n",
    "        valid_loss = _test_epoch(model, valid_iterator, criterion)\n",
    "\n",
    "        valid_loss = valid_loss\n",
    "        print('validation loss %.5f' % valid_loss)\n",
    "\n",
    "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
    "        history = history.append(record, ignore_index=True)\n",
    "\n",
    "        if early_stopping > 0:\n",
    "            if valid_loss > prev_loss:\n",
    "                es_epochs += 1\n",
    "            else:\n",
    "                es_epochs = 0\n",
    "\n",
    "            if es_epochs >= early_stopping:\n",
    "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
    "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
    "                break\n",
    "\n",
    "            prev_loss = min(prev_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6f9560ba82b4586439a423694189080aa5db43d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e8559afedb4aa5ae5f40e20f297917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=22744, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss 0.55416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f4d82a61514363b1533840b03ff546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1', max=22744, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation loss 0.55050\n"
     ]
    }
   ],
   "source": [
    "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, scheduler=scheduler, \n",
    "        n_epochs=2, early_stopping=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "d3407f604184e25e966bc11c2e7e8077237534d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_accuracy(model, iterator):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with tt.no_grad():\n",
    "        for batch in iterator:\n",
    "            output = model(batch)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(batch.label.view_as(pred)).sum().item()\n",
    "    return 100. * correct / len(iterator.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "74c09541332a9861f18568a5d6f0e50b7b053cbf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.6445891000465"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_accuracy(model, test_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
